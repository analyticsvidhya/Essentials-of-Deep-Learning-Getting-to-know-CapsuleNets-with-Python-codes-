{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "input_num_units = 784\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "\n",
    "# create model\n",
    "model = Sequential([\n",
    " Dense(units=hidden_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dense(units=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile the model with necessary attributes\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential([\n",
    " InputLayer(input_shape=input_reshape),\n",
    "\n",
    "Convolution2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    "Convolution2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    "Convolution2D(25, 4, 4, activation='relu'),\n",
    "\n",
    "Flatten(),\n",
    "\n",
    "Dense(output_dim=hidden_num_units, activation='relu'),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capsule Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapsNet(input_shape, n_class, routings):\n",
    "    x = layers.Input(shape=input_shape)\n",
    " \n",
    "    # Layer 1: Just a conventional Conv2D layer\n",
    "    conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    " \n",
    "    # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "    primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    " \n",
    "    # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "    digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "    name='digitcaps')(primarycaps)\n",
    " \n",
    "    # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "    # If using tensorflow, this will not be necessary. :)\n",
    "    out_caps = Length(name='capsnet')(digitcaps)\n",
    " \n",
    "    # Decoder network.\n",
    "    y = layers.Input(shape=(n_class,))\n",
    "    masked_by_y = Mask()([digitcaps, y]) # The true label is used to mask the output of capsule layer. For training\n",
    "    masked = Mask()(digitcaps) # Mask using the capsule with maximal length. For prediction\n",
    " \n",
    "    # Shared Decoder model in training and prediction\n",
    "    decoder = models.Sequential(name='decoder')\n",
    "    decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
    "    decoder.add(layers.Dense(1024, activation='relu'))\n",
    "    decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "    decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    " \n",
    "    # Models for training and evaluation (prediction)\n",
    "    train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "    eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    " \n",
    "    # manipulate model\n",
    "    noise = layers.Input(shape=(n_class, 16))\n",
    "    noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "    masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "    manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    " \n",
    "    return train_model, eval_model, manipulate_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Walkthrough of CapsNet on MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.misc import imread\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "from keras import layers, models, optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stop potential randomness\n",
    "seed = 128\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.path.abspath('.')\n",
    "data_dir = os.path.join(root_dir, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = rng.choice(train.filename)\n",
    "filepath = os.path.join(data_dir, 'train', img_name)\n",
    "\n",
    "img = imread(filepath, flatten=True)\n",
    "\n",
    "pylab.imshow(img, cmap='gray')\n",
    "pylab.axis('off')\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for img_name in train.filename:\n",
    "   image_path = os.path.join(data_dir, 'train', img_name)\n",
    "   img = imread(image_path, flatten=True)\n",
    "   img = img.astype('float32')\n",
    "   temp.append(img)\n",
    " \n",
    "train_x = np.stack(temp)\n",
    "\n",
    "train_x /= 255.0\n",
    "train_x = train_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "temp = []\n",
    "for img_name in test.filename:\n",
    "   image_path = os.path.join(data_dir, 'test', img_name)\n",
    "   img = imread(image_path, flatten=True)\n",
    "   img = img.astype('float32')\n",
    "   temp.append(img)\n",
    " \n",
    "test_x = np.stack(temp)\n",
    "\n",
    "test_x /= 255.0\n",
    "test_x = test_x.reshape(-1, 784).astype('float32')\n",
    "\n",
    "train_y = keras.utils.np_utils.to_categorical(train.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_size = int(train_x.shape[0]*0.7)\n",
    "\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vars\n",
    "input_num_units = 784\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 128\n",
    "\n",
    "# import keras modules\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer, Convolution2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# create model\n",
    "model = Sequential([\n",
    " Dense(units=hidden_num_units, input_dim=input_num_units, activation='relu'),\n",
    " Dense(units=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "# compile the model with necessary attributes\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model.fit(train_x, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data\n",
    "train_x_temp = train_x.reshape(-1, 28, 28, 1)\n",
    "val_x_temp = val_x.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# define vars\n",
    "input_shape = (784,)\n",
    "input_reshape = (28, 28, 1)\n",
    "\n",
    "\n",
    "pool_size = (2, 2)\n",
    "\n",
    "hidden_num_units = 50\n",
    "output_num_units = 10\n",
    "\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    " InputLayer(input_shape=input_reshape),\n",
    "\n",
    "Convolution2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    "Convolution2D(25, 5, 5, activation='relu'),\n",
    " MaxPooling2D(pool_size=pool_size),\n",
    "\n",
    "Convolution2D(25, 4, 4, activation='relu'),\n",
    "\n",
    "Flatten(),\n",
    "\n",
    "Dense(output_dim=hidden_num_units, activation='relu'),\n",
    "\n",
    "Dense(output_dim=output_num_units, input_dim=hidden_num_units, activation='softmax'),\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#trained_model_conv = model.fit(train_x_temp, train_y, nb_epoch=epochs, batch_size=batch_size, validation_data=(val_x_temp, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
    "def train_generator(x, y, batch_size, shift_fraction=0.1):\n",
    "   train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "   height_shift_range=shift_fraction) # shift up to 2 pixel for MNIST\n",
    "   generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "   while 1:\n",
    "     x_batch, y_batch = generator.next()\n",
    "     yield ([x_batch, y_batch])\n",
    " \n",
    "# Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "trained_model2 = model.fit_generator(generator=train_generator(train_x_temp, train_y, 1000, 0.1),\n",
    " steps_per_epoch=int(train_y.shape[0] / 1000),\n",
    " epochs=epochs,\n",
    " validation_data=[val_x_temp, val_y])\n",
    "# End: Training with data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CapsNet(input_shape, n_class, routings):\n",
    "   \"\"\"\n",
    "   A Capsule Network on MNIST.\n",
    "   :param input_shape: data shape, 3d, [width, height, channels]\n",
    "   :param n_class: number of classes\n",
    "   :param routings: number of routing iterations\n",
    "   :return: Two Keras Models, the first one used for training, and the second one for evaluation.\n",
    "   `eval_model` can also be used for training.\n",
    "   \"\"\"\n",
    "   x = layers.Input(shape=input_shape)\n",
    "\n",
    "   # Layer 1: Just a conventional Conv2D layer\n",
    "   conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "   # Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "   primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "   # Layer 3: Capsule layer. Routing algorithm works here.\n",
    "   digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "   name='digitcaps')(primarycaps)\n",
    "\n",
    "   # Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "   # If using tensorflow, this will not be necessary. :)\n",
    "   out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "   # Decoder network.\n",
    "   y = layers.Input(shape=(n_class,))\n",
    "   masked_by_y = Mask()([digitcaps, y]) # The true label is used to mask the output of capsule layer. For training\n",
    "   masked = Mask()(digitcaps) # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "   # Shared Decoder model in training and prediction\n",
    "   decoder = models.Sequential(name='decoder')\n",
    "   decoder.add(layers.Dense(512, activation='relu', input_dim=16*n_class))\n",
    "   decoder.add(layers.Dense(1024, activation='relu'))\n",
    "   decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "   decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "   # Models for training and evaluation (prediction)\n",
    "   train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "   eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "   # manipulate model\n",
    "   noise = layers.Input(shape=(n_class, 16))\n",
    "   noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "   masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "   manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "   return train_model, eval_model, manipulate_model\n",
    "\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "   \"\"\"\n",
    "   Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "   :param y_true: [None, n_classes]\n",
    "   :param y_pred: [None, num_capsule]\n",
    "   :return: a scalar loss value.\n",
    "   \"\"\"\n",
    "   L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "   0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "   return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, eval_model, manipulate_model = CapsNet(input_shape=train_x_temp.shape[1:],\n",
    " n_class=len(np.unique(np.argmax(train_y, 1))),\n",
    " routings=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001),\n",
    " loss=[margin_loss, 'mse'],\n",
    " loss_weights=[1., 0.392],\n",
    " metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
    "def train_generator(x, y, batch_size, shift_fraction=0.1):\n",
    " train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    " height_shift_range=shift_fraction) # shift up to 2 pixel for MNIST\n",
    " generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    " while 1:\n",
    " x_batch, y_batch = generator.next()\n",
    " yield ([x_batch, y_batch], [y_batch, x_batch])\n",
    "\n",
    "# Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "trained_model3 = model.fit_generator(generator=train_generator(train_x_temp, train_y, 1000, 0.1),\n",
    " steps_per_epoch=int(train_y.shape[0] / 1000),\n",
    " epochs=epochs)\n",
    "# End: Training with data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(trained_model.history['val_acc'], 'r', trained_model2.history['val_acc'], 'b', trained_model3.history['val_capsnet_acc'], 'g')\n",
    "plt.legend(('MLP', 'CNN', 'CapsNet'),\n",
    " loc='lower right', fontsize='large')\n",
    "plt.title('Validation Accuracies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
